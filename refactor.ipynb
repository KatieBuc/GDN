{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19ffd3ed910>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from datasets.TimeDataset import TimeDataset\n",
    "from util.env import *\n",
    "from util.time import *\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_edge_index(org_edge_index, batch_num, n_nodes):\n",
    "\n",
    "    edge_index = org_edge_index.clone().detach()\n",
    "    edge_num = org_edge_index.shape[1]\n",
    "    batch_edge_index = edge_index.repeat(1, batch_num).contiguous()\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        batch_edge_index[:, i * edge_num : (i + 1) * edge_num] += i * n_nodes\n",
    "\n",
    "    return batch_edge_index.long()\n",
    "\n",
    "\n",
    "class OutLayer(nn.Module):\n",
    "    def __init__(self, in_num, layer_num, inter_num=512):\n",
    "        super(OutLayer, self).__init__()\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        for i in range(layer_num):\n",
    "            # last layer, output shape:1\n",
    "            if i == layer_num - 1:\n",
    "                modules.append(nn.Linear(in_num if layer_num == 1 else inter_num, 1))\n",
    "            else:\n",
    "                layer_in_num = in_num if i == 0 else inter_num\n",
    "                modules.append(nn.Linear(layer_in_num, inter_num))\n",
    "                modules.append(nn.BatchNorm1d(inter_num))\n",
    "                modules.append(nn.ReLU())\n",
    "\n",
    "        self.mlp = nn.ModuleList(modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "\n",
    "        for mod in self.mlp:\n",
    "            if isinstance(mod, nn.BatchNorm1d):\n",
    "                out = out.permute(0, 2, 1)\n",
    "                out = mod(out)\n",
    "                out = out.permute(0, 2, 1)\n",
    "            else:\n",
    "                out = mod(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class GNNLayer(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, inter_dim=0, heads=1):\n",
    "        super(GNNLayer, self).__init__()\n",
    "\n",
    "        self.gnn = GraphLayer(\n",
    "            in_channel, out_channel, inter_dim=inter_dim, heads=heads, concat=False\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, embedding=None):\n",
    "\n",
    "        out, (new_edge_index, att_weight) = self.gnn(\n",
    "            x, edge_index, embedding, return_attention_weights=True\n",
    "        )\n",
    "\n",
    "        self.att_weight_1 = att_weight\n",
    "        self.edge_index_1 = new_edge_index\n",
    "\n",
    "        out = self.bn(out)\n",
    "\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class GDN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fc_edge_idx,\n",
    "        n_nodes,\n",
    "        embed_dim=64,\n",
    "        out_layer_inter_dim=256,\n",
    "        input_dim=10,\n",
    "        out_layer_num=1,\n",
    "        topk=20,\n",
    "    ):\n",
    "\n",
    "        super(GDN, self).__init__()\n",
    "\n",
    "        self.fc_edge_idx = fc_edge_idx\n",
    "        self.n_nodes = n_nodes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.out_layer_inter_dim = out_layer_inter_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.out_layer_num = out_layer_num\n",
    "        self.topk = topk\n",
    "\n",
    "    def _initialise_layers(self):\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_nodes, self.embed_dim)\n",
    "        nn.init.kaiming_uniform_(self.embedding.weight, a=math.sqrt(5))\n",
    "\n",
    "        self.bn_outlayer_in = nn.BatchNorm1d(self.embed_dim)\n",
    "\n",
    "        self.gnn_layers = nn.ModuleList(\n",
    "            [\n",
    "                GNNLayer(\n",
    "                    self.input_dim,\n",
    "                    self.embed_dim,\n",
    "                    inter_dim=2 * self.embed_dim,\n",
    "                    heads=1,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.node_embedding = None\n",
    "        self.learned_graph = None\n",
    "\n",
    "        self.out_layer = OutLayer(\n",
    "            self.embed_dim, self.out_layer_num, inter_num=self.out_layer_inter_dim\n",
    "        )\n",
    "\n",
    "        self.cache_fc_edge_idx = None\n",
    "        self.cache_embed_index = None\n",
    "\n",
    "        self.dp = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x = data.clone().detach()\n",
    "        device = data.device\n",
    "        batch_num, n_nodes, all_feature = x.shape\n",
    "        x = x.view(-1, all_feature).contiguous()\n",
    "\n",
    "        if self.cache_fc_edge_idx is None:\n",
    "            self.cache_fc_edge_idx = get_batch_edge_index(\n",
    "                self.fc_edge_index, batch_num, n_nodes\n",
    "            ).to(device)\n",
    "\n",
    "        all_embeddings = self.embedding(torch.arange(n_nodes).to(device))  # v_i's\n",
    "\n",
    "        weights_arr = all_embeddings.detach().clone()\n",
    "        all_embeddings = all_embeddings.repeat(batch_num, 1)\n",
    "\n",
    "        weights = weights_arr.view(n_nodes, -1)\n",
    "\n",
    "        cos_ji_mat = torch.matmul(weights, weights.T)  # e_{ji} in eqn (2)\n",
    "        normed_mat = torch.matmul(\n",
    "            weights.norm(dim=-1).view(-1, 1), weights.norm(dim=-1).view(1, -1)\n",
    "        )\n",
    "        cos_ji_mat = cos_ji_mat / normed_mat\n",
    "\n",
    "        topk_indices_ji = torch.topk(cos_ji_mat, self.topk, dim=-1)[\n",
    "            1\n",
    "        ]  # A_{ji} in eqn (3)\n",
    "\n",
    "        self.learned_graph = topk_indices_ji\n",
    "\n",
    "        gated_i_ = torch.arange(0, n_nodes)\n",
    "        gated_i = (\n",
    "            gated_i_.permute(*torch.arange(gated_i_.ndim - 1, -1, -1))\n",
    "            .unsqueeze(1)\n",
    "            .repeat(1, self.topk)\n",
    "            .flatten()\n",
    "            .to(device)\n",
    "            .unsqueeze(0)\n",
    "        )\n",
    "\n",
    "        gated_j = topk_indices_ji.flatten().unsqueeze(0)\n",
    "        gated_edge_index = torch.cat((gated_j, gated_i), dim=0)\n",
    "\n",
    "        batch_gated_edge_index = get_batch_edge_index(\n",
    "            gated_edge_index, batch_num, n_nodes\n",
    "        ).to(device)\n",
    "\n",
    "        gcn_out = self.gnn_layers(\n",
    "            x,\n",
    "            batch_gated_edge_index,\n",
    "            embedding=all_embeddings,\n",
    "        )\n",
    "        gcn_out = gcn_out.view(batch_num, n_nodes, -1)\n",
    "\n",
    "        idxs = torch.arange(0, n_nodes).to(device)\n",
    "        out = torch.mul(gcn_out, self.embedding(idxs))\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = F.relu(self.bn_outlayer_in(out))  # eqn (5)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.dp(out)\n",
    "        out = self.out_layer(out)\n",
    "        out = out.view(-1, n_nodes)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNAD:\n",
    "    \"\"\"\n",
    "    Graph Neural Network-based Anomaly Detection in Multivariate Timeseries.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch: int = 128,\n",
    "        epoch: int = 100,\n",
    "        slide_win: int = 15,\n",
    "        dim: int = 64,\n",
    "        slide_stride: int = 5,\n",
    "        comment: str = \"\",\n",
    "        random_seed: int = 0,\n",
    "        out_layer_num: int = 1,\n",
    "        out_layer_inter_dim: int = 256,\n",
    "        decay: float = 0,\n",
    "        validate_ratio: float = 0.1,\n",
    "        topk: int = 20,\n",
    "        save_path_pattern: str = \"msl\",\n",
    "        dataset: str = \"msl\",\n",
    "        device: str = \"cpu\",\n",
    "        report: str = \"best\",\n",
    "        load_model_path: str = \"\",\n",
    "    ):\n",
    "\n",
    "        self.batch = batch\n",
    "        self.epoch = epoch\n",
    "        self.slide_win = slide_win\n",
    "        self.dim = dim\n",
    "        self.slide_stride = slide_stride\n",
    "        self.comment = comment\n",
    "        self.random_seed = random_seed\n",
    "        self.out_layer_num = out_layer_num\n",
    "        self.out_layer_inter_dim = out_layer_inter_dim\n",
    "        self.decay = decay\n",
    "        self.validate_ratio = validate_ratio\n",
    "        self.topk = topk\n",
    "        self.save_path_pattern = save_path_pattern\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.report = report\n",
    "        self.load_model_path = load_model_path\n",
    "\n",
    "    def _split_train_validation(self, data):\n",
    "\n",
    "        dataset_len = len(data)\n",
    "        validate_use_len = int(dataset_len * self.validate_ratio)\n",
    "        validate_start_idx = random.randrange(dataset_len - validate_use_len)\n",
    "        idx = torch.arange(dataset_len)\n",
    "\n",
    "        train_sub_idx = torch.cat(\n",
    "            [idx[:validate_start_idx], idx[validate_start_idx + validate_use_len :]]\n",
    "        )\n",
    "        train_subset = Subset(data, train_sub_idx)\n",
    "\n",
    "        validate_sub_idx = idx[\n",
    "            validate_start_idx : validate_start_idx + validate_use_len\n",
    "        ]\n",
    "        validate_subset = Subset(data, validate_sub_idx)\n",
    "\n",
    "        return train_subset, validate_subset\n",
    "\n",
    "    def _load_data(self):\n",
    "\n",
    "        train = pd.read_csv(f\"./data/{self.dataset}/train.csv\", sep=\",\", index_col=0)\n",
    "        test = pd.read_csv(f\"./data/{self.dataset}/test.csv\", sep=\",\", index_col=0)\n",
    "\n",
    "        train = train.drop(columns=[\"attack\"]) if \"attack\" in train.columns else train\n",
    "\n",
    "        feature_list = train.columns[\n",
    "            train.columns.str[0] != \"_\"\n",
    "        ].to_list()  # convention is to pass non-features as '_'\n",
    "        assert len(feature_list) == len(set(feature_list))\n",
    "\n",
    "        fc_struc = {\n",
    "            ft: [x for x in feature_list if x != ft] for ft in feature_list\n",
    "        }  # fully connected structure\n",
    "\n",
    "        edge__idx_tuples = [\n",
    "            (feature_list.index(child), feature_list.index(node_name))\n",
    "            for node_name, node_list in fc_struc.items()\n",
    "            for child in node_list\n",
    "        ]\n",
    "\n",
    "        fc_edge_idx = [\n",
    "            [x[0] for x in edge__idx_tuples],\n",
    "            [x[1] for x in edge__idx_tuples],\n",
    "        ]\n",
    "        fc_edge_idx = torch.tensor(fc_edge_idx, dtype=torch.long)\n",
    "\n",
    "        train_input = _parse_data(train, feature_list)\n",
    "        test_input = _parse_data(test, feature_list, labels=test.attack.tolist())\n",
    "\n",
    "        cfg = {\n",
    "            \"slide_win\": self.slide_win,\n",
    "            \"slide_stride\": self.slide_stride,\n",
    "        }\n",
    "\n",
    "        train_dataset = TimeDataset(train_input, fc_edge_idx, mode=\"train\", config=cfg)\n",
    "        test_dataset = TimeDataset(test_input, fc_edge_idx, mode=\"test\", config=cfg)\n",
    "\n",
    "        train_subset, validate_subset = self._split_train_validation(train_dataset)\n",
    "\n",
    "        # get data loaders\n",
    "        train_dataloader = DataLoader(train_subset, batch_size=self.batch, shuffle=True)\n",
    "\n",
    "        validate_dataloader = DataLoader(\n",
    "            validate_subset, batch_size=self.batch, shuffle=False\n",
    "        )\n",
    "\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset, batch_size=self.batch, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "        # save to self\n",
    "        self.fc_edge_idx = fc_edge_idx\n",
    "        self.feature_list = feature_list\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.validate_dataloader = validate_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "\n",
    "    def _load_model(self):\n",
    "        # instantiate model\n",
    "        model = GDN(\n",
    "            self.fc_edge_idx,\n",
    "            n_nodes=len(self.feature_list),\n",
    "            dim=self.dim,\n",
    "            input_dim=self.slide_win,\n",
    "            out_layer_num=self.out_layer_num,\n",
    "            out_layer_inter_dim=self.out_layer_inter_dim,\n",
    "            topk=self.topk,\n",
    "        ).to(self.device)\n",
    "\n",
    "        model._initialise_layers()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self):\n",
    "        self._load_data()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "def _parse_data(data, feature_list, labels=None):\n",
    "\n",
    "    labels = [0] * data.shape[0] if labels == None else labels\n",
    "    res = data[feature_list].T.values.tolist()\n",
    "    res.append(labels)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1,  2,  3,  ..., 23, 24, 25],\n",
       "         [ 0,  0,  0,  ..., 26, 26, 26]])]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_sets = []\n",
    "edge_index_sets.append(fitted_model.fc_edge_idx)\n",
    "edge_index_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, edge_index in enumerate(edge_index_sets):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNAD()\n",
    "fitted_model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fitted_model.feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1,  2,  3,  ..., 23, 24, 25],\n",
       "         [ 0,  0,  0,  ..., 26, 26, 26]])]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.fc_edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor to module\n",
    "#    - init: dataloaders, GDN\n",
    "#    - run: train, test, check output\n",
    "# write unit tests\n",
    "# --------------------\n",
    "\n",
    "# get interactive validation screen\n",
    "# plots like paper\n",
    "# error handling for real data!\n",
    "\n",
    "# --------------------\n",
    "# ideas for research (graph metrics, input node-related anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('gdn_old')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99f10b4e66e58daffdd3587f8013f35f7438a354bd317537c02f690a0bc2561c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
