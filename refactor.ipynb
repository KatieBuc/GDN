{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from refactor import GNNAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(f\"./data/msl/train.csv\", sep=\",\", index_col=0)\n",
    "X_train = X_train.drop(columns=[\"attack\"]) if \"attack\" in X_train.columns else X_train\n",
    "X_test = pd.read_csv(f\"./data/msl/test.csv\", sep=\",\", index_col=0)\n",
    "y_test = X_test.attack.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNAD(shuffle_train=False)\n",
    "fitted_model = model.fit(X_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n10907700\\Anaconda3\\envs\\gdn_old\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.validation import check_random_state\n",
    "\n",
    "from refactor import GNNAD\n",
    "\n",
    "random_state = 245\n",
    "rng = check_random_state(random_state)\n",
    "\n",
    "# generate multivariate data\n",
    "cov = [[0.5, 0.3, 0], [0.3, 1.0, 0], [0, 0, 0.8]]\n",
    "mean = [1, 3, 10]\n",
    "X_train = (\n",
    "    pd.DataFrame(rng.multivariate_normal(mean=mean, cov=cov, size=2000))\n",
    "    .ewm(span=2)\n",
    "    .mean()\n",
    ")\n",
    "X_test = (\n",
    "    pd.DataFrame(rng.multivariate_normal(mean=mean, cov=cov, size=1000))\n",
    "    .ewm(span=2)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# add anomalies to the test set\n",
    "X_test.iloc[342:356, :] *= 2\n",
    "X_test.iloc[752:772, 0:2] *= 0.01\n",
    "\n",
    "# anomaly labels\n",
    "y_test = np.zeros(len(X_test))\n",
    "y_test[342:356] = 1\n",
    "y_test[752:772] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (0 / 10) (Loss:40.17884064, ACU_loss:120.53652191)\n",
      "epoch (1 / 10) (Loss:39.03404490, ACU_loss:117.10213470)\n",
      "epoch (2 / 10) (Loss:37.60780589, ACU_loss:112.82341766)\n",
      "epoch (3 / 10) (Loss:36.32013067, ACU_loss:108.96039200)\n",
      "epoch (4 / 10) (Loss:35.13179779, ACU_loss:105.39539337)\n",
      "epoch (5 / 10) (Loss:34.05962372, ACU_loss:102.17887115)\n",
      "epoch (6 / 10) (Loss:34.34579849, ACU_loss:103.03739548)\n",
      "epoch (7 / 10) (Loss:33.31120809, ACU_loss:99.93362427)\n",
      "epoch (8 / 10) (Loss:32.25991440, ACU_loss:96.77974319)\n",
      "epoch (9 / 10) (Loss:31.17664210, ACU_loss:93.52992630)\n",
      "=========================** Result **============================\n",
      "\n",
      "F1 score: 0.5384615384615384\n",
      "precision: 0.8235294117647058\n",
      "recall: 0.4117647058823529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GNNAD(shuffle_train=False, topk=2, epoch=10)\n",
    "fitted_model = model.fit(X_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.f1\n",
    "fitted_model.precision\n",
    "fitted_model.recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GNNAD(shuffle_train=False, threshold_type=\"max_validation\")\n",
    "fitted_model2 = model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "test_labels = fitted_model.test_result[2, :, 0].tolist()\n",
    "plt.plot(np.array(test_labels));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refactor import eval_scores, get_full_err_scores\n",
    "\n",
    "test_scores = get_full_err_scores(fitted_model.test_result)\n",
    "plt.plot(test_scores.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_err_scores = test_scores\n",
    "gt_labels = test_labels\n",
    "topk = 1\n",
    "\n",
    "\n",
    "total_features = total_err_scores.shape[0]\n",
    "\n",
    "# finds topk feature idx of max scores for each time point\n",
    "topk_indices = np.argpartition(\n",
    "    total_err_scores, range(total_features - topk - 1, total_features), axis=0\n",
    ")[-topk:]\n",
    "\n",
    "# for each time, sum the topk error scores\n",
    "total_topk_err_scores = np.sum(\n",
    "    np.take_along_axis(total_err_scores, topk_indices, axis=0), axis=0\n",
    ")\n",
    "\n",
    "final_topk_fmeas, thresolds = eval_scores(\n",
    "    total_topk_err_scores, gt_labels, return_thresold=True\n",
    ")  # scores, true_scores\n",
    "\n",
    "th_i = final_topk_fmeas.index(max(final_topk_fmeas))\n",
    "thresold = thresolds[th_i]\n",
    "\n",
    "pred_labels = np.zeros(len(total_topk_err_scores))\n",
    "pred_labels[total_topk_err_scores > thresold] = 1\n",
    "\n",
    "for i in range(len(pred_labels)):\n",
    "    pred_labels[i] = int(pred_labels[i])\n",
    "    gt_labels[i] = int(gt_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr, rankdata\n",
    "\n",
    "th_steps = 400\n",
    "true_scores = gt_labels\n",
    "scores = total_topk_err_scores\n",
    "\n",
    "padding_list = [0] * (len(true_scores) - len(scores))\n",
    "\n",
    "if len(padding_list) > 0:\n",
    "    scores = padding_list + scores\n",
    "\n",
    "scores_sorted = rankdata(scores, method=\"ordinal\")  # rank of score\n",
    "th_vals = np.array(range(th_steps)) * 1.0 / th_steps\n",
    "fmeas = [None] * th_steps\n",
    "thresholds = [None] * th_steps\n",
    "\n",
    "i = 0\n",
    "cur_pred = scores_sorted > th_vals[i] * len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores_sorted, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(thresolds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(topk_indices[0], \"o\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py -dataset msl -device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('gdn_old')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99f10b4e66e58daffdd3587f8013f35f7438a354bd317537c02f690a0bc2561c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
