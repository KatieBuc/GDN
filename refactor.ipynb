{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19ffd3ed910>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from datasets.TimeDataset import TimeDataset\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNAD():\n",
    "    \"\"\"\n",
    "    Graph Neural Network-based Anomaly Detection in Multivariate Timeseries.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        batch: int = 128,\n",
    "        epoch: int = 100,\n",
    "        slide_win: int = 15,\n",
    "        dim: int = 64,\n",
    "        slide_stride: int = 5,\n",
    "        comment: str = '',\n",
    "        random_seed: int = 0,\n",
    "        out_layer_num: int = 1,\n",
    "        out_layer_inter_dim: int = 256,\n",
    "        decay: float = 0,\n",
    "        validate_ratio: float = 0.1,\n",
    "        topk: int = 20,\n",
    "        save_path_pattern: str = 'msl',\n",
    "        dataset: str = 'msl',\n",
    "        device: str = 'cpu',\n",
    "        report: str = 'best',\n",
    "        load_model_path: str = '',\n",
    "        ):\n",
    "\n",
    "        self.batch = batch\n",
    "        self.epoch = epoch\n",
    "        self.slide_win = slide_win\n",
    "        self.dim = dim\n",
    "        self.slide_stride = slide_stride\n",
    "        self.comment = comment\n",
    "        self.random_seed = random_seed\n",
    "        self.out_layer_num = out_layer_num\n",
    "        self.out_layer_inter_dim = out_layer_inter_dim\n",
    "        self.decay = decay\n",
    "        self.validate_ratio = validate_ratio\n",
    "        self.topk = topk\n",
    "        self.save_path_pattern = save_path_pattern\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.report = report\n",
    "        self.load_model_path = load_model_path\n",
    "\n",
    "\n",
    "    def _split_train_validation(self, data):\n",
    "\n",
    "        dataset_len = len(data)\n",
    "        validate_use_len = int(dataset_len * self.validate_ratio)\n",
    "        validate_start_idx = random.randrange(dataset_len - validate_use_len)\n",
    "        idx = torch.arange(dataset_len)\n",
    "\n",
    "        train_sub_idx = torch.cat([idx[:validate_start_idx], idx[validate_start_idx+validate_use_len:]])\n",
    "        train_subset = Subset(data, train_sub_idx)\n",
    "\n",
    "        validate_sub_idx = idx[validate_start_idx:validate_start_idx+validate_use_len]\n",
    "        validate_subset = Subset(data, validate_sub_idx)\n",
    "\n",
    "        return train_subset, validate_subset\n",
    "\n",
    "\n",
    "    def _load_data(self):\n",
    "\n",
    "        train = pd.read_csv(f'./data/{self.dataset}/train.csv', sep=',', index_col=0)\n",
    "        test = pd.read_csv(f'./data/{self.dataset}/test.csv', sep=',', index_col=0)\n",
    "\n",
    "        train = train.drop(columns=['attack']) if 'attack' in train.columns else train\n",
    "        \n",
    "        feature_list = train.columns[train.columns.str[0] != '_'].to_list() # convention is to pass non-features as '_'\n",
    "        assert len(feature_list) == len(set(feature_list))\n",
    "\n",
    "        fc_struc = {ft: [x for x in feature_list if x != ft] for ft in feature_list} # fully connected structure\n",
    "\n",
    "        edge__idx_tuples = [(feature_list.index(child), feature_list.index(node_name)) \n",
    "        for node_name, node_list in fc_struc.items() for child in node_list]\n",
    "\n",
    "        fc_edge_idx = [[x[0] for x in edge__idx_tuples], [x[1] for x in edge__idx_tuples]]\n",
    "        fc_edge_idx = torch.tensor(fc_edge_idx, dtype = torch.long)\n",
    "\n",
    "        train_input = _parse_data(train, feature_list)\n",
    "        test_input = _parse_data(test, feature_list, labels=test.attack.tolist())\n",
    "\n",
    "        cfg = {\n",
    "            'slide_win': self.slide_win,\n",
    "            'slide_stride': self.slide_stride,\n",
    "        }\n",
    "        \n",
    "        train_dataset = TimeDataset(train_input, fc_edge_idx, mode='train', config=cfg)\n",
    "        test_dataset = TimeDataset(test_input, fc_edge_idx, mode='test', config=cfg)\n",
    "\n",
    "        train_subset, validate_subset = self._split_train_validation(train_dataset)\n",
    "\n",
    "        # get data loaders\n",
    "        train_dataloader = DataLoader(train_subset, batch_size=self.batch,\n",
    "                                shuffle=True)\n",
    "\n",
    "        validate_dataloader = DataLoader(validate_subset, batch_size=self.batch,\n",
    "                                shuffle=False)\n",
    "\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=self.batch,\n",
    "                                shuffle=False, num_workers=0)\n",
    "        \n",
    "        # instantiate model\n",
    "        model = GDN([fc_edge_idx],\n",
    "            len(feature_list), \n",
    "            dim=self.dim, \n",
    "            input_dim=self.slide_win,\n",
    "            out_layer_num=self.out_layer_num,\n",
    "            out_layer_inter_dim=self.out_layer_inter_dim,\n",
    "            topk=self.topk\n",
    "        ).to(self.device)\n",
    "\n",
    "        # save to self\n",
    "        self.feature_list = feature_list\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.validate_dataloader = validate_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self):\n",
    "        self._load_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _parse_data(data, feature_list, labels=None):\n",
    "\n",
    "    labels = [0]*data.shape[0] if labels == None else labels\n",
    "    res = data[feature_list].T.values.tolist()\n",
    "    res.append(labels)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNAD()\n",
    "model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor to module\n",
    "#    - init: dataloaders, GDN\n",
    "#    - run: train, test, check output\n",
    "# write unit tests\n",
    "#--------------------\n",
    "\n",
    "# get interactive validation screen\n",
    "# plots like paper\n",
    "# error handling for real data!\n",
    "\n",
    "#--------------------\n",
    "# ideas for research (graph metrics, input node-related anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('gdn_old')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99f10b4e66e58daffdd3587f8013f35f7438a354bd317537c02f690a0bc2561c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
